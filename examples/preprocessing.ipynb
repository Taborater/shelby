{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from shelby import basics as sbasics\n",
    "from shelby import pull_push_data as sdata\n",
    "from shelby import data_cleaning as scleaning\n",
    "from shelby import data_preparation as sprep\n",
    "from shelby import modeling as smodeling\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic operations\n",
    "\n",
    "\n",
    "**Using:**\n",
    "- pull_push_data\n",
    "    - load data from csv\n",
    "    \n",
    "- basics\n",
    "    - separate columns by types\n",
    "    - stack dfs\n",
    "    \n",
    "- data_cleaning\n",
    "    - correct finall df's columns' types\n",
    "    \n",
    "**Steps:**\n",
    "- Load data\n",
    "- Stack train and test\n",
    "- Separate columns and correct types of full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Load data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = sdata.read_data(train_path='./data/train.csv',\n",
    "                                    test_path='./data/test.csv',\n",
    "                                    index_col='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Stack train and test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df, target_col, test_start_index = sbasics.train_test_stack(df_train=df_train,\n",
    "                                                                df_test=df_test,\n",
    "                                                                target_col_name='SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Separate columns and correct types of finall df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols, num_cols = sbasics.separate_cols(full_df,\n",
    "                                           unique_thresh=20,\n",
    "                                           return_probably_cat=False)\n",
    "\n",
    "full_df = scleaning.TypesCorrector(num_cols=num_cols,\n",
    "                                   cat_cols=cat_cols).fit_transform(full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "**Using:**\n",
    "- data_cleaning\n",
    "    - filling NaNs\n",
    "    \n",
    "- data_preparation\n",
    "    - remove skew from skewed num_features\n",
    "    - get dummies for categorical columns\n",
    "    - get array representation of data and split full_df back to train and test\n",
    "    \n",
    "**Steps:**\n",
    "- Init sklearn.pipeline.Pipeline\n",
    "- Apply pipeline to full_df\n",
    "- Log-transformation of the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Init sklearn.pipeline.Pipeline_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipeline = Pipeline([\n",
    "    ('Fill NaNs in numerical columns with 0',          scleaning.NumNanFiller(num_cols, method=0)),\n",
    "    ('Fill NaNs in categorical columns with NO VALUE', scleaning.CatNanFiller(cat_cols, method='indicator')),\n",
    "    ('Remove Skew from numerical columns',             sprep.SkewRemover(num_cols, method='log')),\n",
    "    ('Generate dummies for categorical features',      sprep.CatDummifier(cat_cols)),\n",
    "    ('Get data in array representation',               sprep.ArraysExtractor(target_col, test_start_index))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Apply it!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_finall = preprocessing_pipeline.fit_transform(full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Log-transformation of the target variable_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log1p(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data\n",
    "**Steps:**\n",
    "- Check array (just a quick look)\n",
    "- Check shapes \n",
    "- Check NaNs\n",
    "- Check dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Check arrays_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "\n",
      " [[6.500000e+01 9.042040e+00 2.003000e+03 ... 1.000000e+00 0.000000e+00\n",
      "  0.000000e+00]\n",
      " [8.000000e+01 9.169622e+00 1.976000e+03 ... 0.000000e+00 0.000000e+00\n",
      "  0.000000e+00]\n",
      " [6.800000e+01 9.328213e+00 2.001000e+03 ... 1.000000e+00 0.000000e+00\n",
      "  0.000000e+00]\n",
      " ...\n",
      " [6.600000e+01 9.109746e+00 1.941000e+03 ... 0.000000e+00 0.000000e+00\n",
      "  1.000000e+00]\n",
      " [6.800000e+01 9.181735e+00 1.950000e+03 ... 0.000000e+00 0.000000e+00\n",
      "  1.000000e+00]\n",
      " [7.500000e+01 9.204121e+00 1.965000e+03 ... 1.000000e+00 0.000000e+00\n",
      "  0.000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print('X:\\n\\n',X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:\n",
      "\n",
      " [12.24769912 12.10901644 12.31717117 ... 12.49313327 11.86446927\n",
      " 11.90159023]\n"
     ]
    }
   ],
   "source": [
    "print('y:\\n\\n',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_finall:\n",
      "\n",
      " [[8.000000e+01 9.360742e+00 1.961000e+03 ... 0.000000e+00 0.000000e+00\n",
      "  1.000000e+00]\n",
      " [8.100000e+01 9.565775e+00 1.958000e+03 ... 0.000000e+00 0.000000e+00\n",
      "  1.000000e+00]\n",
      " [7.400000e+01 9.534668e+00 1.997000e+03 ... 0.000000e+00 0.000000e+00\n",
      "  1.000000e+00]\n",
      " ...\n",
      " [1.600000e+02 9.903538e+00 1.960000e+03 ... 0.000000e+00 0.000000e+00\n",
      "  0.000000e+00]\n",
      " [6.200000e+01 9.253592e+00 1.992000e+03 ... 0.000000e+00 0.000000e+00\n",
      "  0.000000e+00]\n",
      " [7.400000e+01 9.172431e+00 1.993000e+03 ... 0.000000e+00 0.000000e+00\n",
      "  0.000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print('X_finall:\\n\\n',X_finall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Check shapes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape: (1460, 80)\n",
      "X shape: (1460, 359)\n",
      "y shape: (1460,)\n",
      "----\n",
      "df_test shape: (1459, 79)\n",
      "X_finall shape: (1459, 359)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'df_train shape: {df_train.shape}\\nX shape: {X.shape}')\n",
    "print(f'y shape: {y.shape}\\n----')\n",
    "print(f'df_test shape: {df_test.shape}\\nX_finall shape: {X_finall.shape}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Check NaNs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X contain NaNs: False\n",
      "y contain NaNs: False\n",
      "X_finall contain NaNs: False\n"
     ]
    }
   ],
   "source": [
    "print(f'X contain NaNs: {np.isnan(X).any()}')\n",
    "print(f'y contain NaNs: {np.isnan(y).any()}')\n",
    "print(f'X_finall contain NaNs: {np.isnan(X_finall).any()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Check dtypes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X dtype = float32\n",
      "y dtype = float64\n",
      "X_finall dtype = float32\n"
     ]
    }
   ],
   "source": [
    "print(f'X dtype = {X.dtype}')\n",
    "print(f'y dtype = {y.dtype}')\n",
    "print(f'X_finall dtype = {X_finall.dtype}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
